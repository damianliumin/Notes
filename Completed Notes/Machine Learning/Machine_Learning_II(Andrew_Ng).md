# Machine Learning II

Author: 刘闵
Contact me:  191240030@smail.nju.edu.cn
Course: Machine Learning - AndrewNg

## L8 - 神经网络: 表示 Neural Networks: Representation

### 1 神经网络模型

**线性回归与逻辑回归的局限：**非线性假设下为了拟合较为复杂的数据，多项式回归中往往需要数量庞大的feature。这种情况下线性回归和逻辑回归的计算代价过大。
在复杂的**非线性假设**下，我们通常选择**神经网络** Neural Networks。神经网络很早就被提出，不过由于计算量庞大，直到近年才大规模应用于机器学习问题。

**神经元模型-逻辑单元 logistic unit：**每个神经元输入$x$，输出$h_\theta(x)=\frac{1}{1+e^{-\theta^Tx}}$。这里的Sigmoid函数是神经网络的**激活函数** activation function，$\theta$是参数，也称模型的**权重**。绘制模型时，输入可省去**偏置单元** bias unit: $x_0=1$。

神经网络的第一层为**输入层** input layer，用于输入特征；最后一层为**输出层** output layer，用于输出计算结果；其余层为**隐藏层** hidden layer。
不同的**神经网络架构** network architecture中神经元的连接方式不同。

**Notation:**
$a_i^{(j)}$：第$j$层第$i$个单元的**激活项**，即计算并输出的值
$\Theta^{(j)}$：控制第$j$层到第$j+1$层映射函数的**权重矩阵**。若第$j$层有$s_j$个单元，第$j+1$层有$s_{j+1}$个单元，则权重矩阵的维数为$s_j\times(s_{j+1}+1)$

**神经网络与逻辑回归：**神经网络每个神经元与上一层激活项间的关系实质上就是逻辑回归与其输入。不同点在于，神经网络每一层的输入不是模型输入的特征$x_1,x_2,x_3\cdots$，而是上一层输出的$a_1^{(j)},a_2^{(j)},a_3^{(j)}\cdots$，根据为权重矩阵选取的不同参数，可以学习到一些更为有趣且复杂的特征。

### 2 前向传播

**前向传播 Forward Propagation：**计算从输入层的激活项开始，逐层传播，最终传播到输出层.

**神经网络的计算过程：**考虑Layer 2，假设输入层有$x_1, x_2, x_3$
$a^{(2)}_1=g(\Theta_{10}^{(1)}x_0+\Theta_{11}^{(1)}x_1+\Theta_{12}^{(1)}x_2+\Theta_{13}^{(1)}x_3)=g(z^{(2)}_1)$
$a^{(2)}_2=g(\Theta_{20}^{(1)}x_0+\Theta_{21}^{(1)}x_1+\Theta_{22}^{(1)}x_2+\Theta_{23}^{(1)}x_3)=g(z^{(2)}_2)$
$a^{(2)}_3=g(\Theta_{30}^{(1)}x_0+\Theta_{31}^{(1)}x_1+\Theta_{32}^{(1)}x_2+\Theta_{33}^{(1)}x_3)=g(z^{(2)}_3)$
令$x=[x_0\,x_1 \,x_2\,x_3]^T$，$z^{(2)}=[z^{(2)}_1\,z^{(2)}_2\,z^{(2)}_3]^T$
**计算向量化：**
$z^{(2)}=\Theta^{(1)}a^{(1)}$ # 用权重矩阵和Layer 1激活项计算向量$z^{(2)}$
$a^{(2)}=g(z^{(2)})$ # 用$z^{(2)}$计算出Layer 2激活项向量，加上$a^{(2)}_0=1$偏置单元
$z^{(3)}=\Theta^{(2)}a^{(2)}$ # 用权重矩阵和Layer 2激活项计算向量$z^{(3)}$
$a^{(3)}=g(z^{(3)})$ # 用$z^{(3)}$计算出Layer 3激活项向量，加上$a^{(3)}_0=1$偏置单元
$\cdots\cdots$ # 前向传播
$h_\theta(x)=a^{(m)}=g(z^{(m)})$ # 输出层

### 3 多类别分类

神经网络的输出层设置多个单元可实现多类别分类，这实质上是一对多方法的拓展。训练集中数据为$(x^{(i)},y^{(i)})$，其中$y^{(i)}$不再是$1,2,3\cdots$，而是$[1\,0\,0\,\cdots]^T,$$[0\,1\,0\,\cdots]^T,$$[0\,0\,1\,\cdots]^T$中的一个。

## L9 - 神经网络: 学习 Neural Networks: Learning

### 1 代价函数

神经网络的代价函数基于逻辑回归的代价函数，我们重点关注神经网络分类问题的代价函数。

**二元分类：**$K=1$，仅一个输出单元，输出0或1
**多元分类：**$K\geq3$，有$k$个输出单元，输出$y=h_\Theta(x)\in\mathbb{R}^k$

**Notation：**
$\{(x^{(1)},y^{(1)}),(x^{(2)},y^{(2)}),\cdots,(x^{(m)},y^{(m)})\}$：训练集
$L$：神经网络层数
$s_l$：第$l$层除偏置单元外的神经元数量
$(h_\Theta(x))_i$：神经网络的第$i$个输出

基于正则化逻辑回归的代价函数$J(\theta)=-\frac{1}{m}\left[\sum_{i=1}^my^{(i)}\log(h_\theta(x))+(1-y^{(i)})\log(1-h_\theta(x^{(i)}))\right]+\frac{\lambda}{2m}\sum_{j=1}^n\theta_j^2$，
可以得到**神经网络的代价函数**：
$$
J(\Theta)=-\frac{1}{m} \left [\sum_{i=1}^m\sum_{k=1}^Ky_k^{(i)}\log(h_\theta(x))_k+(1-y^{(i)}_k)\log(1-(h_\theta(x^{(i)}))_k)\right]\\+\frac{\lambda}{2m}\sum_{l=1}^{L-1}\sum_{i=1}^{s_l}\sum_{j=1}^{s_{l+1}}(\Theta_{ji}^{(l)})^2
$$

这个代价函数是正则化的，习惯上$i$从1开始取值。

### 2 反向传播算法

为了找到参数$\Theta$来最小化，需要使用梯度下降法或其他的高级优化算法。因此，我们需要计算$J(\Theta)$和$\frac{\part}{\part\Theta^{(l)}_{ij}}J(\Theta)$，我们已经有了前者，现在重点关注**偏导项**。

**梯度计算 - 前向传播**
$a^{(1)}=x$
$z^{(2)}=\Theta^{(1)}a^{(1)}$
$a^{(2)}=g(z^{(2)})$ (add $a^{(2)}_0$)
$z^{(3)}=\Theta^{(2)}a^{(2)}$
$a^{(3)}=g(z^{(3)})$ (add $a^{(3)}_0$)
$\cdots\cdots$
$z^{(L)}=\Theta^{(L-1)}a^{(L-1)}$
$a^{(L)}=h_\Theta(x)=g(z^{(L)})$ 
**梯度计算 - 反向传播**
$\delta^{(l)}_j$：第$l$层第$j$个神经元的**误差项**
输出层：$\delta^{(l)}=a^{(L)}-y$
其余层：$\delta^{(j)}=(\Theta^{(j)})^T\delta^{(j+1)}.*g'(z^{(j)})=(\Theta^{(j)})^T\delta^{(j+1)}.*[a^{(j)}.*(1-a^{(j)})]$
其中.*为pairwise operation。由于从输出层向前计算，我们称之为反向传播。$\delta^{(1)}$无需计算，因为输入层不存在误差。另外，可以证明在不考虑$\lambda$或$\lambda=0$的情况下，$\frac{\part}{\part\Theta^{(l)}_{ij}}J(\Theta)=a^{(l)}_j\delta_i^{(l+1)}$.

**反向传播算法 Backpropagation algorithm：** {
Training Set $\{(x^{(1)},y^{(1)}),(x^{(2)},y^{(2)}),\cdots,(x^{(m)},y^{(m)})\}$
Set $\Delta^{(l)}_{ij}=0$ for all $l,i,j$ 
For $i=1$ to $m$
	Set $a^{(1)}=x^{(i)}$
	Perform forward propagation to compute $a^{(l)}$ for $l=2,3,\cdots,L$
	Using $y^{(i)}$, compute $\delta^{(l)}=a^{(L)}-y^{(i)}$
	Perform backprop to compute $\delta^{(l)}$ for $l=L-1,L-2,\cdots,2$
	$\Delta^{(l)}:=\Delta^{(l)}+\delta^{(l+1)}(a^{(l)})^T$ for $l=1,2,\cdots,L-1$

$D_{ij}^{(l)}:=\frac{1}{m}\Delta^{(l)}+\lambda\Theta_{ij}^{(l)}$   if $j\neq 0$
$D_{ij}^{(l)}:=\frac{1}{m}\Delta^{(l)}$   if $j = 0$
}

这个算法目标是计算出$\frac{\part}{\part\Theta^{(l)}_{ij}}J(\Theta)$，计算结果保存在$D_{ij}^{(l)}$内。遍历训练集的for循环内，先用前向传播计算出激活项$a^{(l)}$，然后用后向传播计算出误差项$\delta^{(l)}$，最后将计算结果累加到$\Delta^{(l)}$内。循环结束后，根据$\Delta^{(l)}$的结果并考虑正则项，计算出$D^{(l)}_{ij}$。

### 3 梯度检验

在复杂的计算模型中，**反向传播算法**或相似的梯度下降算法实现时很容易出现bug。有时整个过程表现得很正常，$J(\Theta)$会逐渐下降到一个最小值，但最终模型仍有很大的误差。**梯度检验** gradient checking可以大幅降低出错得可能性，在这类模型中建议使用梯度检验来确保代码的正确性。

**梯度检验原理：**利用**双侧差分**计算出导数近似值，将近似值与反向传播的结果比较.
(双侧差分$\frac{\part}{\part\theta}J(\theta)\approx\frac{J(\theta+\epsilon)-J(\theta-\epsilon)}{2\epsilon}$的准确性高于单侧差分$\frac{J(\theta+\epsilon)-J(\theta)}{\epsilon}$，通常$\epsilon=10^{-4}$即可)

**梯度检验：**将神经网络中的所有参数$\Theta^{(l)}$展开成一个长向量$\theta=[\theta_1,\theta_2,\cdots,\theta_n]$，接下来验证：
$\frac{\part}{\part\theta_1}J(\theta)\approx\frac{J(\theta_1+\epsilon,\theta_2,\cdots,\theta_n)-J(\theta_1-\epsilon,\theta_2,\cdots,\theta_n)}{2\epsilon}$
$\frac{\part}{\part\theta_2}J(\theta)\approx\frac{J(\theta_1,\theta_2+\epsilon,\cdots,\theta_n)-J(\theta_1,\theta_2-\epsilon,\cdots,\theta_n)}{2\epsilon}$
$\cdots\cdots$
$$\frac{\part}{\part\theta_n}J(\theta)\approx\frac{J(\theta_1,\theta_2,\cdots,\theta_n+\epsilon)-J(\theta_1,\theta_2,\cdots,\theta_n-\epsilon)}{2\epsilon}$$
式子左边为反向传播的计算结果，右边为双侧差分计算出的近似值.

**反向传播与梯度检验的实现：**
1.反向传播计算
2.梯度检验计算
3.比较计算结果
4.若结果无误，**关闭梯度检验**进行训练(梯度检验的计算代价很高)

### 4 随机初始化

梯度下降法或高级优化算法需要对参数$\theta$初始化。在神经网络模型中，把参数全部初始化为0会造成高度的冗余。如果权重矩阵每行相同，则迭代后每层的神经元完全相同：它们接受同样的参数，有相同的$\alpha^{(l)}_j$和$\delta^{(l)}_j$。实际上最后每个逻辑回归单元仅得到一个特征。这就是**对称权重问题**，可通过随机初始化解决。

通常将$\Theta^{(l)}_{ij}$初始化为$[-\epsilon,\epsilon]$间的随机值，然后再进行训练。

### 5 神经网络实践

**神经网络架构选择：**
输入单元数量：特征$x^{(i)}$的维度
输出单元数量：类型数
默认架构：大多数情况下，一个隐藏层是最好的选择。如果有多余一个隐藏层，每个隐藏层的神经元数量应该相同。隐藏神经元的数量越多则效果越好，但是计算量也会更大。

**神经网络训练：**

1. 对权重矩阵随机初始化
2. 对训练集中的数据，用前向传播计算出$h_\Theta(x^{(i)})$
3. 计算代价函数$J(\Theta)$
4. 反向传播计算出偏导项$\frac{\part}{\part\Theta_{ij}^l}J(\Theta)$
5. 用梯度检验检查反向传播和数值估计的结果，无误后关闭梯度检验
6. 用梯度下降法或高级优化算法，结合反向传播算法，最小化$J(\Theta)$

PS：神经网络的代价函数$J(\Theta)$不是凸函数，理论上使用梯度下降法和高级优化算法等方法的结果可能是局部最优解，但是实践中这样的结果通常已经足够好。

***

## L10 - 应用机器学习的建议 Advice for Applying ML

### 1 机器学习诊断

在模型运行效果与预期相差甚远时，人们通常随机选择下列的某个方法，投入大量时间调试机器学习算法：

+ 使用更多的训练样本
+ 减少/增加特征数量
+ 增加多项式特征数量
+ 增加/减小正则化参数$\lambda$

在大规模项目中，这样盲目的调试可能会浪费很多时间。

**机器学习诊断 Machine Learning Diagnostic：**通过测试来发现机器学习哪一部分出现了问题，获得提高性能方面的指导，确定接下来应该做什么

### 2 评估假设函数

为了评估模型，通常将数据集按照7:3的比例分为**训练集** training set和**测试集** test set。为了衡量假设函数$h_\theta(x)$的表现，需要定义**测试误差** test set error。

**线性回归测试误差：**
$$
J_{test}(\theta)=\frac{1}{2m_{test}}\sum_{i=1}^{m_{test}}(h_\theta(x_{test}^{(i)})-y_{test}^{(i)})^2
$$
**逻辑回归测试误差：**
$$
J_{test}(\theta)=-\frac{1}{m_{test}}\sum_{i=1}^{m_{test}}y_{test}^{(i)}\log h_\theta(x_{test}^{(i)})+(1-y_{test}^{(i)})\log h_\theta(x_{test}^{(i)})
$$
逻辑回归的测试误差还有一个较直观的量度：**错误分类 misclassification error**。定义$err(h_\theta(x),y)=[h_\theta\geq0.5,y=1\,or\,h_\theta<0.5,y=0]$，这里用到艾弗森括号。
$$
Test\,\,error=\frac{1}{m_{test}}\sum_{i=1}^{m_{test}}err(h_\theta(x_{test}^{(i)}),y_\theta^{(i)})
$$

### 3 模型选择与训练/验证/测试集

**模型选择问题：**多项式次数、正则化参数$\lambda$等会影响模型的最终表现，通常需要比较不同模型的表现选择最优的模型。

在选择模型时，通常间数据集按照6:2:2的比例划分为训练集、**(交叉)验证集** cross validation set和**测试集**。这三组数据分别产生如下误差：
**训练误差**：$J_{train}(\theta)=\frac{1}{2m}\sum_{i=1}^{m}(h_\theta(x^{(i)})-y^{(i)})^2$
**验证误差**：$J_{cv}(\theta)=\frac{1}{2m_{cv}}\sum_{i=1}^{m_{cv}}(h_\theta(x_{cv}^{(i)})-y_{cv}^{(i)})^2$
**测试误差**：$J_{test}(\theta)=\frac{1}{2m_{test}}\sum_{i=1}^{m_{test}}(h_\theta(x_{test}^{(i)})-y_{test}^{(i)})^2$
对多个模型选择进行训练后，通过验证集找出$J_{cv}(\theta)$最小的模型。假设不同的模型区别在于多项式次数$d$，那么通过验证集筛选模型的过程实质上是对$d$进行了一次拟合。为了确保模型**泛化误差**较小，还需要通过测试集进行测试。有时将验证集和训练集合并，即用筛选模型的数据集进行测试，也可以得到泛化误差很小的模型，但是最好将其分开。

### 4 正则化与偏差、方差

机器学习的问题通常归为两类：**偏差 bias**较大(欠拟合)和**方差 variance**较大(过拟合)。分清是那种情况对于解决问题十分重要。

考虑多项式次数$d$，训练误差$J_{train}(\theta)$会随着$d$的增大而减小，验证误差$J_{cv}(\theta)$会随着$d$的增大而先减后增。因而可以通过如下方式判断：

+ 偏差：$J_{train}(\theta)$较大
  	$J_{train}(\theta)\approx J_{cv}(\theta)$
+ 方差：$J_{train}(\theta)$较小
      $J_{train}(\theta)\ll J_{cv}(\theta)$

偏差、方差也常与正则化参数$\lambda$相关。过大的$\lambda$会导致高偏差，过小的$\lambda$会导致高方差。与代价函数$J(\theta)$不同的是，$J_{train}(\theta),J_{cv}(\theta),J_{test}(\theta)$中不考虑正则化项。$J_{train}(\theta)$会随着$\lambda$的增大而增大，$J_{cv}(\theta)$会随着$\lambda$的增大而先减后增，通过这种判断可以找到合适的$\lambda$.

### 5 学习曲线

**学习曲线 learning curves**可以有效判断是高偏差还是高方差。学习曲线横轴为训练集规模$m$，纵轴为误差$error$。

**正常情况：**$J_{train}(\theta)$随着训练的规模增大而逐渐增大，$J_{cv}(\theta)$随着训练的规模增大而逐渐变小，两者的差距不大且逐渐缩小。
**高偏差：**$J_{train}(\theta)$随着训练规模的增大而快速上升，达到一定规模后几乎平行于横轴。$J_{cv}(\theta)$随着训练规模增大而逐渐下降，达到一定规模后也趋于平行，且和$J_{train}(\theta)$差距非常小。由此可见，增加训练样本数量不能解决高偏差的情况。
**高方差：**$J_{train}(\theta)$随着训练规模的增大而逐渐增大，$J_{cv}(\theta)$随着训练的规模增大而逐渐变小，但两者差距始终较大。从趋势上来看，两者最终会接近，因而增加训练样本可以改善高方差的情况。

实践中曲线可能有较多的噪声，但是总体趋势通常是符合上文描述的。

### 6 解决问题

了解了如何诊断出高偏差和高方差的问题后，可以针对问题采用不同方案，避免盲目尝试造成的时间浪费。

+ 使用更多的训练样本 -> 高方差
+ 减少特征数量 -> 高方差
+ 增加特征数量 -> 高偏差
+ 增加多项式特征数量 -> 高偏差
+ 增加正则化参数$\lambda$ -> 高方差
+ 减小正则化参数$\lambda$ -> 高偏差

另外，针对神经网络也有一些建议：小规模的神经网络计算代价小，但容易欠拟合。大规模的神经网络计算代价大，容易过拟合，但是通过正则化通常可以有更好的性能。神经网络的隐藏层数量通常设为1，若需要更多隐藏层，可通过验证集进行模型选择。

***

## L11 - 机器学习系统设计 Machine Learning System Design

### 1 误差分析

在实现一个大型的机器学习项目前，建议先实现一个简单的算法，对其进行**误差分析 error analysis**并通过**数值评估 numerical evaluation**评价表现：

+ 手动分析验证集中**出错样本**的共性，寻找解决方案
+ 通过一个**数值度量标准**衡量每个模型的表现

### 2 不对称分类的误差评估

**偏斜类 skewed classes**是指分类问题中正样本与负样本数量比较十分悬殊。如果采用一般的数值评估方法，即计算出测试样本的误差率，无法正确反映模型的表现。例如，某一模型的准确度为99%，看上去很不错了。但是考虑只有0.5%的样本是正类，这样的表现就不那么好了。相比之下，如果一个模型永远输出$y=0$，准确度为99.5%，甚至高于一个训练过的模型，显然它的预测准确度不能反映其表现。

分类问题中，预测结果与实际分类的组合如下：

| predicted\actual | 1              | 0              |
| :--------------: | -------------- | -------------- |
|        1         | True Positive  | False Positive |
|        0         | False Negative | True Negative  |

在不对称分类的情况下，通过**查准率 precision**和**召回率 recall**来衡量模型表现.

**查准率：**$\frac{true\,\,pos}{predicted\,\,pos}=\frac{true\,\,pos}{true\,\,pos+false\,\,pos}$
查准率是预测为1的样本中真正为1的比例
**召回率：**$\frac{true\,\,pos}{actual\,\,pos}=\frac{true\,\,pos}{true\,\,pos+false\,\,neg}$
召回率是真正为1的样本中预测出为1的比例

### 3 查准率与召回率的权衡

通常分类器需要在查准率和召回率之间权衡。逻辑回归中在$h_\theta(x)\geq threshold$时预测$y=1$，在$h_\theta(x)<threshold$时预测$y=0$。阈值越高，预测1时越有把握，查准率越高，召回率越低；相反，阈值越低，预测0时越有把握，查准率越低，召回率越高。

由于这两个度量标准此消彼长， 不同的算法有时很难直接根据它们进行取舍。我们定义**F值**($F_1$ score)，$F=2\frac{PR}{P+R}$。这样的定义给召回率和查准率中较低的那个更高的权重，同时确保取值范围在$[0,1]$之间。

### 4 机器学习数据

关于机器学习的数据可以考虑以下两个方面：

1. 人类专家应该能够从提供给算法的数据$x$中预测$y$
2. 算法有足够的参数，数据有足够的特征与规模

在上述条件下，大多数算法都可以有相似的表现。

***

## L12 - 支持向量机 Support Vector Machines

### 1 优化目标

逻辑回归中代价函数是$J(\theta)=-\frac{1}{m}\sum_{i=1}^m[y\log(h_\theta(x))+(1-y)\log(1-h_\theta(x))]$，考虑其中的式子$-y\log\frac{1}{1+e^{-\theta^Tx}}-(1-y)\log(1-\frac{1}{1+e^{-\theta^Tx}})$。
如果$y=1$，期待$\theta^Tx\geq 0$。此时上式变为$-\log\frac{1}{1+e^{-\theta^Tx}}$，将$z=\theta^Tx$视为变量，定义函数$cost_1(z)$，该函数在$z\geq 1$时为0，$z<1$是一条斜率为负的直线，与上式贴近；
同理，$y=0$时期待$\theta^Tx<0$。上式变为$-\log(1-\frac{1}{1+e^{-\theta^Tx}})$。定义函数$cost_0(x)$，该函数与$cost_1(x)$关于$y$轴对称，也与上式贴近。

在此基础上，再对逻辑回归代价函数作如下修改：
1.两边同时乘以常数$m$，这不会影响最优的参数$\theta$；
2.取消正则化参数，在第一项前添加常数$C$来平衡两项的关系.

由此可以得到**支持向量机 SVM**的**优化目标：**
$$
\min_\theta C\sum_{i=1}^m\left [y^{(i)}cost_{1}(\theta^Tx^{(i)})+(1-y^{(i)})cost_0(\theta^Tx^{(i)})\right]+\frac{1}{2}\sum_{i=1}^n\theta_j^2
$$
SVM的**假设函数**为：
$$
h_\theta(x)=
\left\{\begin{matrix}
1\,\,\,\,\,\,\,\,\,\,\,\,\,\,if\,\,\theta^Tx\geq0\\ 
0\,\,\,\,\,\,\,\,\,\,\,\,\,\,\,\,otherwise
\end{matrix}\right.\\
$$

### 2 SVM大间隔

由于$cost_1,cost_0$函数的特点，发现SVM希望$y=1$时$\theta^Tx\geq1$，$y=0$时$\theta^T\leq-1$。在$C$非常大的情况下，优化目标第一项应变为0，此时优化问题等价于：

+ 计算$\theta$最小化$\frac{1}{2}\sum_{i=1}^n\theta_j^2$，满足$\theta^Tx\geq1$ if $y=1$，$\theta^Tx\leq-1$ if $y=0$.

这个优化问题会使得SVM不仅能完成分类，还会选择与两边数据有最大**间隔** margin的决策边界，因此SVM也被称为**大间隔分类器** large margin classifier。这种特性增强了SVM分类器的鲁棒性。

实践中，过大的$C$会导致SVM对异常数据敏感，从而影响间隔。合适大小的$C$能帮助SVM提高对异常数据的耐受程度。

**数学原理：**
从向量的角度，$\frac{1}{2}\sum_{i=1}^n\theta_j^2=\frac{1}{2}\left\|\theta\right\|^2$，$\theta^Tx^{(i)}=p^{(i)}\left\|\theta\right\|$，其中$p^{(i)}$是$x^{(i)}$在$\theta$上的投影。另外，$\theta^Tx=0$意味着$\theta$与决策边界正交。若SVM的决策边界的间隔很小，会存在一些样本在$\theta$上的投影很小，为了满足$p^{(i)}\left\|\theta\right\|\geq1$或$p^{(i)}\left\|\theta\right\|\leq-1$，$\|\theta\|$会因此变得很大，这与优化目标恰好相反。因此，优化后的决策边界会与尽量与样本间保持大间隔。注意这个优化问题的前提是在$C$很大。

### 3 核函数

为了得到复杂的非线性函数，通常会选取复杂的多项式$\theta_0+\theta_1f_1+\theta_2f_2+\theta_3f_3+\cdots$，其中$f_1=x_1,f_2=x_2,f_3=x_1x_2,f_4=x_1^2,f_5=x_2^2\cdots$
这种方法会面临大量的特征选择，复杂问题中计算量很大。我们需要一个找到更好的特征$f_1,f_2,f_3\cdots$的方法。

选取一些**标记 landmarks**：$l^{(1)},l^{(2)},l^{(3)},\cdots$，给定$x$向量时，可以计算$x$与这些标记的接近程度，从而得到新的特征$f_1,f_2,f_3,\cdots$.
$$
f_i=similarity(x, l^{(i)})=\exp(-\frac{\left\|x-l^{(i)} \right\|}{2\sigma^2})=\exp(-\frac{\sum_{j=1}^n(x_j-l^{(i)}_j)^2}{2\sigma^2})
$$
这里similarity是相似度函数，即**核函数 kernel**，可写作$k(x,l^{(i)})$。本式中核函数选取的是**高斯核函数 Gauss kernel**，$x$与$l^{(i)}$接近时近似于1，距离较远时近似于0。其中参数$\sigma$越大则下降越慢，反之下降越快。核函数得到的特征能够帮助SVM有效地学习复杂的特征。

**标记选取：**通常我们将训练样本都作为标记，即$l^{(1)}=x^{(1)},l^{(2)}=x^{(2)},\cdots,l^{(m)}=x^{(m)}$. 这样给定$x$后，可得$f_1=k(x,l^{(1)}),f_2=k(x,l^{(2)}),\cdots,f_m=k(x,l^{(m)})$，添加$f_0=1$.

**SVM与核函数：**
给定$x$，计算出特征$f\in\mathbb{R}^{m+1}$，若$\theta^Tf\geq0$，预测$y=1$
训练时，最小化$C\sum_{i=1}^m\left [y^{(i)}cost_{1}(\theta^Tf^{(i)})+(1-y^{(i)})cost_0(\theta^Tf^{(i)})\right]+\frac{1}{2}\sum_{i=1}^m\theta_j^2$.
SVM与核函数结合有很多提高计算效率的方法，例如将$\theta$的平方和转化为$\theta^TM\theta$来计算，其中$M$与核函数的选取有关。这里的计算方法涉及到很多数学细节，最好直接用软件库优化目标。另外，核函数原理上也可以应用于逻辑回归等其他算法，但是由于一些计算优化无法推广到逻辑回归中，核函数会使得其他算法变慢很多。

**SVM参数：**
$C$：$C$过大时会导致高方差，过小时会导致高偏差.
$\sigma^2$：较大的$\sigma^2$会使特征$f_i$变化较为平滑，可能导致高偏差；较小的$\sigma^2$会使特征$f_i$变化较为剧烈，可能导致高方差.

### 4 SVM应用

**核函数：**SVM可以不使用核函数(或者叫线性核函数 linear kernel)。使用核函数时，除了高斯核函数外，还有很多复杂的核函数可供选择：polynomial kernel, string kernel, chi-square kernel, histogram intersection kernel, ...

**多元分类：**许多SVM软件包已经实现了多元分类的功能，当然也可用一对多方法实现多元分类。

**算法选择：**

+ **特征数相比于样本数很大**，选择逻辑回归/SVM+线性核函数
  这种情况下线性函数已经有很好的表现，这样的数据量也难以训练出复杂的函数
+ **特征少，样本数量适中**，选择SVM+高斯核函数
+ **特征少，样本数量大**，添加特征并选择逻辑回归/SVM+线性核函数
  尽管SVM的核函数在是线上已经优化了很多，但是在庞大的数据量面前，SVM+高斯核函数还是会很慢

神经网络适用于大多数情形，但是训练起来较慢。此外，SVM的优化问题处理的是凸函数，不会遇到局部最优的问题，这对神经网络来说是个不大不小的问题。
此外，逻辑回归和SVM+线性核函数尽管有时在表现上有差异，但是应用场景时互通的。

